version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "80:80"
    environment:
      # Frontend Environment Variables
      - VITE_SPHERE_API_KEY=A5AABB9058C44FCDB3A6E3F248265E21
      - VITE_LONGDO_MAP_API_KEY=12a91099fdf18c01e89d872f6175c84b
      - VITE_API_URL=http://localhost:8000
      - NODE_ENV=production
    depends_on:
      - backend-api
    networks:
      - app-network
    restart: unless-stopped
    
  backend-api:
    build:
      context: ./backend-api
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      # Database
      - DATABASE_URL=postgresql+asyncpg://postgres:postgres@db-service:5432/ai_detection
      - DB_USER=postgres
      - DB_PASSWORD=postgres  
      - DB_HOST=db-service
      - DB_PORT=5432
      - DB_NAME=ai_detection
      
      # Service URLs
      - ML_SERVICE_URL=http://ai-inference-service:8080
      - AI_SERVICE_URL=http://ai-inference-service:8080
      
      # Security
      - JWT_SECRET_KEY=1f7e6056d57d55fc13a004f569057dfcd6136259ef9a39b9d7fe95dcd80cbef9
      - SECRET_KEY=1f7e6056d57d55fc13a004f569057dfcd6136259ef9a39b9d7fe95dcd80cbef9
      
      # Cloudinary
      - CLOUDINARY_CLOUD_NAME=ddzwlyj5y
      - CLOUDINARY_API_KEY=579724167749572
      - CLOUDINARY_API_SECRET=qQqWaPMZDNEDTbf7Fo6p5YkOXhs
      
      # API Settings
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - DEBUG=false
      - LOG_LEVEL=INFO
      - ENVIRONMENT=production
    depends_on:
      db-service:
        condition: service_healthy
      ai-inference-service:
        condition: service_started
    networks:
      - app-network
    restart: unless-stopped
    
  ai-inference-service:
    build:
      context: ./ai-inference-service
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      # AI Service Settings
      - HOST=0.0.0.0
      - PORT=8080
      - MODEL_PATH=/app/model
      - AI_MODE=segment_only
      - LOG_LEVEL=INFO
      - DEBUG=false
      - ENVIRONMENT=production
    volumes:
      - ./ai-inference-service/model:/app/model
    networks:
      - app-network
    restart: unless-stopped

  db-service:
    build:
      context: ./postgres
      dockerfile: Dockerfile
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=ai_detection
      - POSTGRES_HOST_AUTH_METHOD=trust
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d ai_detection"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

networks:
  app-network:
    driver: bridge

volumes:
  postgres_data: